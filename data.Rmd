# Data 

## Sources

The data we need for our study is available in Bloomberg Terminal Application, accessible in Columbia University's Library Bloomberg Terminal.  Phillip Kim spent a morning at the library, and used the export Data function for each of the data items listed below and their respective Bloomberg functions.  The exported data is then saved into individual worksheets within an Excel workbook named "bloomberg Data PK.xlsx"

The primary hurdle that we faced in data collection was realizing that the intraday pricing history for the SP500 futures was only trailing one year from the download date.  That will limit our dependent variable of each day's closing returns to only one year of data.

### E-mini Futures
Bloomberg identifier: ES1 Index
Fields: Price (LAST_PRICE) and Volume (VOLUME)
Details: Choose 15 minute pricing interval going as far back as possible.  This returns us data from 10/17/2021 18:00 to 11/1/2022 10:15am, a total of 23585 rows.

### Net Positioning
Bloomberg identifier: IMMOENCN Index
Fields: LAST_PRICE
Details: This net positioning data is a weekly series of non-commercial net-positioning against our SP500 futures.  We downloaded 669 rows of data since 1/31/2010, but since our data starts 10/17/2021 we'll only use about 53 weeks of data.

### Market Valuation
Bloomberg Identifier: SPX Index
Fields: PE_RATIO
Details: P/E ratio data is daily, and we downloaded data all the way back to 2010 (3230 rows).  Since our pricing data starts 10/17/2021, we'll only use 259 rows of data.

### Market Volatility
Bloomberg Identifier: VIX Index
Fields: LAST_PRICE
Details: The VIX index is a daily series, and we downloaded data all the way back to 2010 (3234 rows).  Since our pricing data starts 10/17/2021, we'll only use 263 rows of data. 

### Investor Sentiment
Bloomberg Identifier: AAIIBEAR Index and AAIIBULL Index
Fields: LAST_PRICE
Details: AAII's sentiment index is a weekly survey, and while we plan to use a "Net Bull" sentiment (Bull Sentiment - Bear Sentiment) we must download them individually.  We downloaded 668 rows of weekly data since 2010, and will use 54 rows to cover the 1 year of return pricing data.

### Federal Funds Rate
Bloomberg Identifier: FDFD Index
Fields: LAST_PRICE
Details: The Fed Funds Effective Rate is a daily series, and we downloaded data all the way back to 2010 (3227 rows).  Since our pricing data starts 10/17/2021, we'll only use 259 rows of data. 

### ISM Manufacturing and Services PMI Index
Bloomberg Identifier: NAPMPMI Index and NAPMNMI Index
Fields: LAST_PRICE
Details: The ISM surveys is a monthly series, and we downloaded data all the way back to 2010 (154 rows).  Since our pricing data starts 10/17/2021, we'll only use 13 rows of data. 

## Cleaning / transformation

Since all of the data collected comes from Bloomberg, the data is already structured and doesn't require a lot of cleaning.  After the export and download into a single excel workbook, we performed two phases of transformation:

### Creating return series

Our futures data comes in the form of prices at each 15 minute interval.  We captured critical interval prices, and created a daily return series that measures various time-to-close (t-15min, 30, 45, 60, 75, 90, 105 to 120min) ranging from t-15min to t-120min.  In addition, we also created a daily return series measuring the open-to-t-15min and open-to-30min, as we'll explore the day-of-return as independent variables.

Finally, each of these return series is transformed into columns assigned to each day, such that for each day, we have returns of t-15-to-close, t-30-to-close, etc.

### Combining independent variables with pricing series

Since most of the independent variables are weekly or monthly, we have to backfill those data series with latest data available.


## Missing value analysis

The data sets that we've chosen are all highly structured pricing, transaction, or survey data that have no missing data.  All the pricing and market data, takes the latest date available.  The only data point missing is the latest data for ISM/Services because the latest point wasn't released.

```{r, include=FALSE}
# load data

library("lubridate")
library("readxl")
es1_df <- read_excel("Bloomberg Data PK.xlsx",sheet = "ES1 COMPLETE")
es1_df$hms <- format(es1_df$DATE, "%H:%M:%S")
es1_df$ymd <- format(es1_df$DATE, "%Y-%m-%d")
es1_eod <- subset(es1_df, (hms >= "14:00:00" & hms <= "16:00:00") )
date_list <- unique(es1_eod$ymd)
es1_eod <- subset(es1_df, (hms >= "14:00:00" & hms <= "16:00:00") | hms == "09:30:00")
es1_eod
es1_eod$CLOSE[es1_eod$ymd == "2022-10-28" & es1_eod$hms == "16:00:00"]
```
```{r, include=FALSE}
days_list <- list()
t15_list <- list()
t30_list <- list()
t45_list <- list()
t60_list <- list()
t75_list <- list()
t90_list <- list()
t105_list <- list()
t120_list <- list()

pre_t15_list <- list()
pre_t30_list <- list()

s15_list <- list()
s30_list <- list()
s45_list <- list()
s60_list <- list()
s75_list <- list()
s90_list <- list()
s105_list <- list()
s120_list <- list()

for (x in date_list) {
  close <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "16:00:00"]
  t15 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "15:45:00"]
  t30 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "15:30:00"]
  t45 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "15:15:00"]
  t60 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "15:00:00"]
  t75 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "14:45:00"]
  t90 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "14:30:00"]
  t105 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "14:15:00"]
  t120 <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "14:00:00"]
  open <- es1_eod$CLOSE[es1_eod$ymd == x & es1_eod$hms == "09:30:00"]
  
  t15_return <- (close / t15) - 1
  t30_return <- (close / t30) - 1
  t45_return <- (close / t45) - 1
  t60_return <- (close / t60) - 1
  t75_return <- (close / t75) - 1
  t90_return <- (close / t90) - 1
  t105_return <- (close / t105) - 1
  t120_return <- (close / t120) - 1
  
  pre_t15_return <- (t15 / open) - 1
  pre_t30_return <- (t30 / open) - 1
  
  s15_return <- (t105 / t120) - 1
  s30_return <- (t90 / t120) - 1
  s45_return <- (t75 / t120) - 1
  s60_return <- (t60 / t120) - 1
  s75_return <- (t45 / t120) - 1
  s90_return <- (t30 / t120) - 1
  s105_return <- (t15 / t120) - 1
  s120_return <- (close / t120) - 1
  
  days_list <- append(days_list, x)
  t15_list <- append(t15_list, t15_return)
  t30_list <- append(t30_list, t30_return)
  t45_list <- append(t45_list, t45_return)
  t60_list <- append(t60_list, t60_return)
  t75_list <- append(t75_list, t75_return)
  t90_list <- append(t90_list, t90_return)
  t105_list <- append(t105_list, t105_return)
  t120_list <- append(t120_list, t120_return)
  
  pre_t15_list <- append(pre_t15_list, pre_t15_return)
  pre_t30_list <- append(pre_t30_list, pre_t30_return)
  
  s15_list <- append(s15_list, s15_return)
  s30_list <- append(s30_list, s30_return)
  s45_list <- append(s45_list, s45_return)
  s60_list <- append(s60_list, s60_return)
  s75_list <- append(s75_list, s75_return)
  s90_list <- append(s90_list, s90_return)
  s105_list <- append(s105_list, s105_return)
  s120_list <- append(s120_list, s120_return)
}

#print(length(pre_t15_list))

eod_returns <- data.frame(unlist(days_list), unlist(t15_list), unlist(t30_list), unlist(t45_list), unlist(t60_list), unlist(t75_list), unlist(t90_list), unlist(t105_list), unlist(t120_list), unlist(pre_t15_list), unlist(pre_t30_list), unlist(s15_list), unlist(s30_list), unlist(s45_list), unlist(s60_list), unlist(s75_list), unlist(s90_list), unlist(s105_list), unlist(s120_list))
names(eod_returns) <- c("Date", "t15_return", "t30_return", "t45_return", "t60_return", "t75_return", "t90_return", "t105_return", "t120_return", "pre_t15_return", "pre_t30_return", "s15_return", "s30_return", "s45_return", "s60_return", "s75_return", "s90_return", "s105_return", "s120_return")
eod_returns$Day_of_Week <- with(eod_returns, wday(eod_returns$Date, label=TRUE))
eod_returns
```
```{r, include=FALSE}
library(lubridate)
eod_returns_pos <- eod_returns[c("Date","t15_return", "pre_t15_return")]
colnames(eod_returns_pos)[which(names(eod_returns_pos) == "Date")] <- "DATE"
eod_returns_pos <- subset(eod_returns_pos, pre_t15_return > 0.02 )
eod_returns_pos$t15_return <- format(round(eod_returns_pos$t15_return,4),nsmall=4)
eod_returns_pos$pre_t15_return <- format(round(eod_returns_pos$pre_t15_return,4),nsmall=4)

eod_returns_pos
```

```{r, include=FALSE}
library(lubridate)
eod_returns1 <- eod_returns
#eod_returns1[['Date']] <- as.POSIXct(eod_returns1[,c('Date')], format = "%Y-%m-%d")
colnames(eod_returns1)[which(names(eod_returns1) == "Date")] <- "DATE"

eod_returns1
```

```{r, include=FALSE}
library(plyr)
es1_volume <- read_excel("Bloomberg Data PK.xlsx",sheet = "ES1 VOLUME")
vix <- read_excel("Bloomberg Data PK.xlsx",sheet = "VIX")
spratio <- read_excel("Bloomberg Data PK.xlsx",sheet = "S&P PE RATIO")
fedfunds <- read_excel("Bloomberg Data PK.xlsx",sheet = "FED FUNDS EFF")

combined <- join_all(list(es1_volume, vix, spratio, fedfunds), by='DATE', type='inner')
combined
```
```{r, include=FALSE}
netpos <- read_excel("Bloomberg Data PK.xlsx",sheet = "ES1 NET POSITION")

combined1 = transform(combined, ES1_NET_POSITION = netpos[max.col(-abs(outer(DATE, netpos$DATE, `-`))), "ES1_NET_POSITION"])
combined1
```
```{r, include=FALSE}
aaii <- read_excel("Bloomberg Data PK.xlsx",sheet = "AAII")

combined2 = transform(combined1, BEAR = aaii[max.col(-abs(outer(DATE, aaii$DATE, `-`))), "BEAR"])
combined2 = transform(combined2, NEUTRAL = aaii[max.col(-abs(outer(DATE, aaii$DATE, `-`))), "NEUTRAL"])
combined2 = transform(combined2, BULL = aaii[max.col(-abs(outer(DATE, aaii$DATE, `-`))), "BULL"])
combined2$NETBULL = combined2$BULL - combined2$BEAR 

combined2
```
```{r, include=FALSE}
ism <- read_excel("Bloomberg Data PK.xlsx",sheet = "ISM")

combined3 = transform(combined2, ISM_MAN = ism[max.col(-abs(outer(DATE, ism$DATE, `-`))), "ISM_MAN"])
combined3 = transform(combined3, ISM_SER = ism[max.col(-abs(outer(DATE, ism$DATE, `-`))), "ISM_SER"])

combined3$DATE <- format(combined2$DATE, "%Y-%m-%d")

combined3
```
```{r}
library(mi)
full_table <- merge(eod_returns1, combined3, by = "DATE")
#drop_cols <- c("Date")
#full_table <- full_table[,!(names(full_table) %in% drop_cols)]
image(missing_data.frame(full_table))
```

